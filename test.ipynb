{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "28976dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 256, 64, 1)]      0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 128)               1838688   \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 256, 64, 1)        1717601   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3556289 (13.57 MB)\n",
      "Trainable params: 3552321 (13.55 MB)\n",
      "Non-trainable params: 3968 (15.50 KB)\n",
      "_________________________________________________________________\n",
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " encoder_input (InputLayer)  [(None, 256, 64, 1)]         0         []                            \n",
      "                                                                                                  \n",
      " encoder_conv_layer_1 (Conv  (None, 128, 32, 512)         5120      ['encoder_input[0][0]']       \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_relu_1 (ReLU)       (None, 128, 32, 512)         0         ['encoder_conv_layer_1[0][0]']\n",
      "                                                                                                  \n",
      " encoder_bn_1 (BatchNormali  (None, 128, 32, 512)         2048      ['encoder_relu_1[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " encoder_conv_layer_2 (Conv  (None, 64, 16, 256)          1179904   ['encoder_bn_1[0][0]']        \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_relu_2 (ReLU)       (None, 64, 16, 256)          0         ['encoder_conv_layer_2[0][0]']\n",
      "                                                                                                  \n",
      " encoder_bn_2 (BatchNormali  (None, 64, 16, 256)          1024      ['encoder_relu_2[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " encoder_conv_layer_3 (Conv  (None, 32, 8, 128)           295040    ['encoder_bn_2[0][0]']        \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_relu_3 (ReLU)       (None, 32, 8, 128)           0         ['encoder_conv_layer_3[0][0]']\n",
      "                                                                                                  \n",
      " encoder_bn_3 (BatchNormali  (None, 32, 8, 128)           512       ['encoder_relu_3[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " encoder_conv_layer_4 (Conv  (None, 16, 4, 64)            73792     ['encoder_bn_3[0][0]']        \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_relu_4 (ReLU)       (None, 16, 4, 64)            0         ['encoder_conv_layer_4[0][0]']\n",
      "                                                                                                  \n",
      " encoder_bn_4 (BatchNormali  (None, 16, 4, 64)            256       ['encoder_relu_4[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " encoder_conv_layer_5 (Conv  (None, 8, 4, 32)             18464     ['encoder_bn_4[0][0]']        \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " encoder_relu_5 (ReLU)       (None, 8, 4, 32)             0         ['encoder_conv_layer_5[0][0]']\n",
      "                                                                                                  \n",
      " encoder_bn_5 (BatchNormali  (None, 8, 4, 32)             128       ['encoder_relu_5[0][0]']      \n",
      " zation)                                                                                          \n",
      "                                                                                                  \n",
      " flatten_8 (Flatten)         (None, 1024)                 0         ['encoder_bn_5[0][0]']        \n",
      "                                                                                                  \n",
      " mu (Dense)                  (None, 128)                  131200    ['flatten_8[0][0]']           \n",
      "                                                                                                  \n",
      " log_variance (Dense)        (None, 128)                  131200    ['flatten_8[0][0]']           \n",
      "                                                                                                  \n",
      " encoder_output (Lambda)     (None, 128)                  0         ['mu[0][0]',                  \n",
      "                                                                     'log_variance[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1838688 (7.01 MB)\n",
      "Trainable params: 1836704 (7.01 MB)\n",
      "Non-trainable params: 1984 (7.75 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 128)]             0         \n",
      "                                                                 \n",
      " decoder_dense (Dense)       (None, 1024)              132096    \n",
      "                                                                 \n",
      " reshape_8 (Reshape)         (None, 8, 4, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_40 (Conv2  (None, 16, 4, 32)         9248      \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " decoder_relu_5 (ReLU)       (None, 16, 4, 32)         0         \n",
      "                                                                 \n",
      " decoder_bn_5 (BatchNormali  (None, 16, 4, 32)         128       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_41 (Conv2  (None, 32, 8, 64)         18496     \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " decoder_relu_4 (ReLU)       (None, 32, 8, 64)         0         \n",
      "                                                                 \n",
      " decoder_bn_4 (BatchNormali  (None, 32, 8, 64)         256       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_42 (Conv2  (None, 64, 16, 128)       73856     \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " decoder_relu_3 (ReLU)       (None, 64, 16, 128)       0         \n",
      "                                                                 \n",
      " decoder_bn_3 (BatchNormali  (None, 64, 16, 128)       512       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_43 (Conv2  (None, 128, 32, 256)      295168    \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " decoder_relu_2 (ReLU)       (None, 128, 32, 256)      0         \n",
      "                                                                 \n",
      " decoder_bn_2 (BatchNormali  (None, 128, 32, 256)      1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv2d_transpose_44 (Conv2  (None, 256, 64, 512)      1180160   \n",
      " DTranspose)                                                     \n",
      "                                                                 \n",
      " decoder_relu_1 (ReLU)       (None, 256, 64, 512)      0         \n",
      "                                                                 \n",
      " decoder_bn_1 (BatchNormali  (None, 256, 64, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " decoder_conv_transpose_lay  (None, 256, 64, 1)        4609      \n",
      " er_5 (Conv2DTranspose)                                          \n",
      "                                                                 \n",
      " sigmoid_layer (Activation)  (None, 256, 64, 1)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1717601 (6.55 MB)\n",
      "Trainable params: 1715617 (6.54 MB)\n",
      "Non-trainable params: 1984 (7.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, ReLU, BatchNormalization, Flatten,\n",
    "    Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
    ")\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Functions to create the autoencoder components\n",
    "def build_encoder(input_shape, conv_filters, conv_kernels, conv_strides, latent_space_dim):\n",
    "    encoder_input = Input(shape=input_shape, name=\"encoder_input\")\n",
    "    x = encoder_input\n",
    "    for i, (filters, kernels, strides) in enumerate(zip(conv_filters, conv_kernels, conv_strides)):\n",
    "        x = Conv2D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernels,\n",
    "            strides=strides,\n",
    "            padding=\"same\",\n",
    "            name=f\"encoder_conv_layer_{i + 1}\"\n",
    "        )(x)\n",
    "        x = ReLU(name=f\"encoder_relu_{i + 1}\")(x)\n",
    "        x = BatchNormalization(name=f\"encoder_bn_{i + 1}\")(x)\n",
    "\n",
    "    shape_before_bottleneck = K.int_shape(x)[1:]\n",
    "    x = Flatten()(x)\n",
    "    mu = Dense(latent_space_dim, name=\"mu\")(x)\n",
    "    log_variance = Dense(latent_space_dim, name=\"log_variance\")(x)\n",
    "\n",
    "    def sample_point_from_normal_distribution(args):\n",
    "        mu, log_variance = args\n",
    "        epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)\n",
    "        return mu + K.exp(log_variance / 2) * epsilon\n",
    "\n",
    "    encoder_output = Lambda(\n",
    "        sample_point_from_normal_distribution,\n",
    "        name=\"encoder_output\"\n",
    "    )([mu, log_variance])\n",
    "\n",
    "    return Model(encoder_input, encoder_output, name=\"encoder\"), shape_before_bottleneck, mu, log_variance\n",
    "\n",
    "\n",
    "def build_decoder(\n",
    "    latent_space_dim, shape_before_bottleneck, conv_filters, conv_kernels, conv_strides\n",
    "):\n",
    "    decoder_input = Input(shape=latent_space_dim, name=\"decoder_input\")\n",
    "    num_neurons = np.prod(shape_before_bottleneck)\n",
    "    x = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
    "    x = Reshape(shape_before_bottleneck)(x)\n",
    "\n",
    "    for i, (filters, kernels, strides) in reversed(list(enumerate(zip(conv_filters, conv_kernels, conv_strides)))):\n",
    "        x = Conv2DTranspose(\n",
    "            filters=filters,\n",
    "            kernel_size=kernels,\n",
    "            strides=strides,\n",
    "            padding=\"same\"  # Ensure output shape consistency\n",
    "        )(x)\n",
    "        x = ReLU(name=f\"decoder_relu_{i + 1}\")(x)\n",
    "        x = BatchNormalization(name=f\"decoder_bn_{i + 1}\")(x)\n",
    "\n",
    "    # Adjust the last layer to produce the expected shape (256, 64, 1)\n",
    "    decoder_output = Conv2DTranspose(\n",
    "        filters=1,\n",
    "        kernel_size=conv_kernels[0],  # Kernel size\n",
    "        strides=(1, 1),  # Adjusted stride\n",
    "        padding=\"same\",  # Ensure same output shape\n",
    "        name=f\"decoder_conv_transpose_layer_{len(conv_filters)}\"\n",
    "    )(x)\n",
    "\n",
    "    output_layer = Activation(\"sigmoid\", name=\"sigmoid_layer\")(decoder_output)\n",
    "\n",
    "    return Model(decoder_input, output_layer, name=\"decoder\")\n",
    "\n",
    "\n",
    "def build_autoencoder(encoder, decoder):\n",
    "    model_input = encoder.input\n",
    "    model_output = decoder(encoder(model_input))\n",
    "    return Model(model_input, model_output, name=\"autoencoder\")\n",
    "\n",
    "\n",
    "# Loss functions\n",
    "def combined_loss(y_target, y_predicted, mu, log_variance, reconstruction_loss_weight):\n",
    "    reconstruction_loss = K.mean(K.square(y_target - y_predicted), axis=[1, 2, 3])\n",
    "    kl_loss = -0.5 * K.sum(1 + log_variance - K.square(mu) - K.exp(log_variance), axis=1)\n",
    "    return reconstruction_loss_weight * reconstruction_loss + kl_loss\n",
    "\n",
    "def save_autoencoder_weights(autoencoder, folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    weights_path = os.path.join(folder, \"weights.h5\")\n",
    "    autoencoder.save_weights(weights_path)\n",
    "\n",
    "# Corrected function to load autoencoder\n",
    "def load_autoencoder(autoencoder, folder):\n",
    "    weights_path = os.path.join(folder, \"weights.h5\")\n",
    "    autoencoder.load_weights(weights_path)\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    input_shape = (256, 64, 1)\n",
    "    conv_filters = (512, 256, 128, 64, 32)\n",
    "    conv_kernels = (3, 3, 3, 3, 3)\n",
    "    conv_strides = (2, 2, 2, 2, (2, 1))\n",
    "    latent_space_dim = 128\n",
    "    reconstruction_loss_weight = 1000000\n",
    "    \n",
    "    encoder, shape_before_bottleneck, mu, log_variance = build_encoder(\n",
    "        input_shape, conv_filters, conv_kernels, conv_strides, latent_space_dim\n",
    "    )\n",
    "    \n",
    "    decoder = build_decoder(\n",
    "        latent_space_dim, shape_before_bottleneck, conv_filters, conv_kernels, conv_strides\n",
    "    )\n",
    "    \n",
    "    autoencoder = build_autoencoder(encoder, decoder)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.legacy.Adam(0.0005)\n",
    "    autoencoder.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=lambda y_true, y_pred: combined_loss(y_true, y_pred, mu, log_variance, reconstruction_loss_weight),\n",
    "        metrics=[MeanSquaredError()],\n",
    "    )\n",
    "    \n",
    "    autoencoder.summary()\n",
    "    encoder.summary()\n",
    "    decoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11adedb4",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to synchronously open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m autoencoder \u001b[38;5;241m=\u001b[39m \u001b[43mload_autoencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mautoencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[66], line 104\u001b[0m, in \u001b[0;36mload_autoencoder\u001b[1;34m(autoencoder, folder)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_autoencoder\u001b[39m(autoencoder, folder):\n\u001b[0;32m    103\u001b[0m     weights_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 104\u001b[0m     \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m autoencoder\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training_v1.py:222\u001b[0m, in \u001b[0;36mModel.load_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39msteps_per_run \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    216\u001b[0m         \u001b[38;5;129;01mnot\u001b[39;00m saving_utils\u001b[38;5;241m.\u001b[39mis_hdf5_filepath(filepath)\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    219\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoad weights is not yet supported with TPUStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    220\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith steps_per_run greater than 1.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    221\u001b[0m         )\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_mismatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_mismatch\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\h5py\\_hl\\files.py:562\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    553\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    554\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    555\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    556\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    557\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    558\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    559\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    560\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    561\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 562\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\h5py\\_hl\\files.py:235\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    234\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 235\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    237\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to synchronously open file (file signature not found)"
     ]
    }
   ],
   "source": [
    "autoencoder = load_autoencoder(autoencoder,'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ab144f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "directory_path = \"spectrograms\"\n",
    "\n",
    "loaded_dict = {}\n",
    "\n",
    "file_list = os.listdir(directory_path)\n",
    "\n",
    "for file_name in file_list:\n",
    "    if file_name.endswith('.npy'):  \n",
    "        file_path = os.path.join(directory_path, file_name)  \n",
    "        array = np.load(file_path)  \n",
    "        array_with_new_axis = np.expand_dims(array, axis=-1)\n",
    "        loaded_dict[file_name] = array_with_new_axis\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a275ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3000 samples\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 1080s 360ms/sample - loss: 30800.4724 - mean_squared_error: 0.0302\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 1052s 351ms/sample - loss: 11229.7112 - mean_squared_error: 0.0109\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 1058s 353ms/sample - loss: 8520.8021 - mean_squared_error: 0.0082\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "batch_size = 64\n",
    "\n",
    "# Check your data generator to ensure it produces batches with the expected shape\n",
    "def data_generator(data_dict, batch_size):\n",
    "    keys = list(data_dict.keys())\n",
    "    while True:\n",
    "        np.random.shuffle(keys)  # Shuffle keys for randomness\n",
    "        for i in range(0, len(keys), batch_size):\n",
    "            key_batch = keys[i:i + batch_size]\n",
    "            x_batch = np.array([data_dict[key] for key in key_batch])\n",
    "            \n",
    "            yield x_batch, x_batch  # Autoencoders expect same input and output\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"best_autoencoder.keras\",\n",
    "    monitor=\"loss\",\n",
    "    save_best_only=True,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "# train_gen = data_generator(loaded_dict, batch_size)\n",
    "# Train the autoencoder\n",
    "\n",
    "keys = list(loaded_dict.keys())\n",
    "train_d = np.array([loaded_dict[key] for key in keys])\n",
    "\n",
    "history = autoencoder.fit(\n",
    "    train_d,\n",
    "    train_d,\n",
    "    batch_size=64,\n",
    "    epochs=3,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8a362bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "import tensorflow as tf \n",
    "\n",
    "def inverse_normalize_spectrogram(normalized_spectrogram, min_val, max_val):\n",
    "    return normalized_spectrogram * (max_val - min_val) + min_val\n",
    "\n",
    "def reconstruct_audio(stft, output_path, min_val, max_val):\n",
    "    stft = stft[:, :, 0]\n",
    "    magnitude_db = inverse_normalize_spectrogram(stft, min_val, max_val)\n",
    "    magnitude_linear = librosa.db_to_amplitude(magnitude_db)\n",
    "    y_reconstructed = librosa.istft(magnitude_linear, hop_length=256)\n",
    "    sf.write(output_path, y_reconstructed, 22050)\n",
    "    \n",
    "    plt.figure(figsize=(10, 4))\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y_reconstructed, n_fft=512, hop_length=256)), ref=np.max)\n",
    "    librosa.display.specshow(D, sr=22050, hop_length=256, x_axis='time', y_axis='linear')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title('Reconstructed Spectrogram')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9b6e09b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m batch_of_images \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([loaded_dict[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m random_keys])\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Reconstruct the images\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m reconstructed_images, latent_representations \u001b[38;5;241m=\u001b[39m \u001b[43mreconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_of_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Corrected: 'reconstructed_images' is already a numpy array\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompare_reconstructed\u001b[39m(reconstructed_images, min_max_dict, random_keys):\n",
      "Cell \u001b[1;32mIn[70], line 8\u001b[0m, in \u001b[0;36mreconstruct\u001b[1;34m(encoder, decoder, batch_of_images)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreconstruct\u001b[39m(encoder, decoder, batch_of_images):\n\u001b[1;32m----> 8\u001b[0m     latent_representations \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_of_images\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     reconstructed_images \u001b[38;5;241m=\u001b[39m decoder\u001b[38;5;241m.\u001b[39mpredict(latent_representations)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reconstructed_images, latent_representations\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training_v1.py:1059\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_call_args(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1058\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_training_loop(x)\n\u001b[1;32m-> 1059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1063\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1069\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training_arrays_v1.py:801\u001b[0m, in \u001b[0;36mArrayLikeTrainingLoop.predict\u001b[1;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    797\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_validate_or_infer_batch_size(batch_size, steps, x)\n\u001b[0;32m    798\u001b[0m x, _, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m_standardize_user_data(\n\u001b[0;32m    799\u001b[0m     x, check_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, steps_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps\u001b[39m\u001b[38;5;124m\"\u001b[39m, steps\u001b[38;5;241m=\u001b[39msteps\n\u001b[0;32m    800\u001b[0m )\n\u001b[1;32m--> 801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training_arrays_v1.py:421\u001b[0m, in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    416\u001b[0m callbacks\u001b[38;5;241m.\u001b[39m_call_batch_hook(\n\u001b[0;32m    417\u001b[0m     mode, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;124m\"\u001b[39m, batch_index, batch_logs\n\u001b[0;32m    418\u001b[0m )\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# Get outputs.\u001b[39;00m\n\u001b[1;32m--> 421\u001b[0m batch_outs \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mins_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_outs, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    423\u001b[0m     batch_outs \u001b[38;5;241m=\u001b[39m [batch_outs]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:4605\u001b[0m, in \u001b[0;36mGraphExecutionFunction.__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   4596\u001b[0m \u001b[38;5;66;03m# Refresh callable if anything has changed.\u001b[39;00m\n\u001b[0;32m   4597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   4599\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m feed_arrays \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feed_arrays\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4603\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m session \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\n\u001b[0;32m   4604\u001b[0m ):\n\u001b[1;32m-> 4605\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeed_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed_symbols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol_vals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msession\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4607\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn(\u001b[38;5;241m*\u001b[39marray_vals, run_metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_metadata)\n\u001b[0;32m   4608\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_fetch_callbacks(fetched[\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fetches) :])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:4530\u001b[0m, in \u001b[0;36mGraphExecutionFunction._make_callable\u001b[1;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[0;32m   4528\u001b[0m     callable_opts\u001b[38;5;241m.\u001b[39mrun_options\u001b[38;5;241m.\u001b[39mCopyFrom(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_options)\n\u001b[0;32m   4529\u001b[0m \u001b[38;5;66;03m# Create callable.\u001b[39;00m\n\u001b[1;32m-> 4530\u001b[0m callable_fn \u001b[38;5;241m=\u001b[39m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_callable_from_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallable_opts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4531\u001b[0m \u001b[38;5;66;03m# Cache parameters corresponding to the generated callable, so that\u001b[39;00m\n\u001b[0;32m   4532\u001b[0m \u001b[38;5;66;03m# we can detect future mismatches and refresh the callable.\u001b[39;00m\n\u001b[0;32m   4533\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callable_fn \u001b[38;5;241m=\u001b[39m callable_fn\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\client\\session.py:1538\u001b[0m, in \u001b[0;36mBaseSession._make_callable_from_options\u001b[1;34m(self, callable_options)\u001b[0m\n\u001b[0;32m   1528\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns a handle to a \"callable\" with the given options.\u001b[39;00m\n\u001b[0;32m   1529\u001b[0m \n\u001b[0;32m   1530\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1535\u001b[0m \u001b[38;5;124;03m  A handle to the new callable.\u001b[39;00m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extend_graph()\n\u001b[1;32m-> 1538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBaseSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Callable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallable_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\client\\session.py:1496\u001b[0m, in \u001b[0;36mBaseSession._Callable.__init__\u001b[1;34m(self, session, callable_options)\u001b[0m\n\u001b[0;32m   1493\u001b[0m options_ptr \u001b[38;5;241m=\u001b[39m tf_session\u001b[38;5;241m.\u001b[39mTF_NewBufferFromString(\n\u001b[0;32m   1494\u001b[0m     compat\u001b[38;5;241m.\u001b[39mas_bytes(callable_options\u001b[38;5;241m.\u001b[39mSerializeToString()))\n\u001b[0;32m   1495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1496\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43mtf_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTF_SessionMakeCallable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m      \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions_ptr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1499\u001b[0m   tf_session\u001b[38;5;241m.\u001b[39mTF_DeleteBuffer(options_ptr)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import os\n",
    "\n",
    "# Function to reconstruct audio from a given encoder, decoder, and batch of images\n",
    "def reconstruct(encoder, decoder, batch_of_images):\n",
    "    latent_representations = encoder.predict(batch_of_images)\n",
    "    reconstructed_images = decoder.predict(latent_representations)\n",
    "    return reconstructed_images, latent_representations\n",
    "\n",
    "# Generate a batch of images for reconstruction\n",
    "n_reconstructions = 5\n",
    "keys = list(loaded_dict.keys())  # Assuming 'loaded_dict' is previously defined\n",
    "random_keys = np.random.choice(keys, n_reconstructions, replace=False)\n",
    "batch_of_images = np.array([loaded_dict[key] for key in random_keys])\n",
    "\n",
    "# Reconstruct the images\n",
    "reconstructed_images, latent_representations = reconstruct(encoder, decoder, batch_of_images)\n",
    "\n",
    "# Corrected: 'reconstructed_images' is already a numpy array\n",
    "def compare_reconstructed(reconstructed_images, min_max_dict, random_keys):\n",
    "    for i, image in enumerate(reconstructed_images):\n",
    "        file_name = random_keys[i]\n",
    "        base_file_name = os.path.splitext(file_name)[0]\n",
    "\n",
    "        # Get min and max values from the dictionary\n",
    "        min_val = min_max_dict[base_file_name]['min']\n",
    "        max_val = min_max_dict[base_file_name]['max']\n",
    "\n",
    "        # Reconstruct audio\n",
    "        reconstruct_audio(image, f\"reconstructed_{file_name}.wav\", min_val, max_val)\n",
    "        reconstruct_audio(loaded_dict[file_name], f\"original_{file_name}.wav\", min_val, max_val)\n",
    "\n",
    "# Load min/max values\n",
    "min_max_dict = np.load('min_max_values.npy', allow_pickle=True).item()\n",
    "\n",
    "# Compare reconstructed images with the original ones\n",
    "compare_reconstructed(reconstructed_images, min_max_dict, random_keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "91a07a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "# Load the audio file\n",
    "audio_path = 'reconstructed_6_yweweler_30.npy.wav'\n",
    "audio_data, sample_rate = librosa.load(audio_path, sr=None)\n",
    "\n",
    "# Amplification factor (e.g., 1.5 to increase by 50%, 2.0 to double the amplitude)\n",
    "amplification_factor = 5000\n",
    "# Amplify the audio by scaling the amplitude\n",
    "amplified_audio = audio_data * amplification_factor\n",
    "\n",
    "# Ensure the amplified audio does not exceed the range [-1, 1] (clip if necessary)\n",
    "amplified_audio = np.clip(amplified_audio, -1, 1)  # Prevent clipping/distortion\n",
    "\n",
    "plt.figure(figsize=(12, 6))  # Set the figure size\n",
    "librosa.display.waveshow(amplified_audio, sr=sample_rate, color='b') \n",
    "\n",
    "output_path = 'amplified_audio.wav'\n",
    "sf.write(output_path, amplified_audio, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9a1edfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_autoencoder(autoencoder, 'model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
